{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовой проект по курсу \"Python для DataScience часть 2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'course_project_test.csv'\n",
    "train_path = 'course_project_train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение модели классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Обзор обучающего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(train_path)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что имеется 7500 наблюдений и 17 признаков, из них один признак - Credit Default - целевой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описание датасета:\n",
    "\n",
    "    Home Ownership - домовладение,\n",
    "    Annual Income - годовой доход,\n",
    "    Years in current job - количество лет на текущем месте работы,\n",
    "    Tax Liens - налоговые обременения,\n",
    "    Number of Open Accounts - количество открытых счетов,\n",
    "    Years of Credit History - количество лет кредитной истории,\n",
    "    Maximum Open Credit - наибольший открытый кредит,\n",
    "    Number of Credit Problems - количество проблем с кредитом,\n",
    "    Months since last delinquent - количество месяцев с последней просрочки платежа,\n",
    "    Bankruptcies - банкротства,\n",
    "    Purpose - цель кредита,\n",
    "    Term - срок кредита,\n",
    "    Current Loan Amount - текущая сумма кредита,\n",
    "    Current Credit Balance - текущий кредитный баланс,\n",
    "    Monthly Debt - ежемесячный долг,\n",
    "    Credit Default - факт невыполнения кредитных обязательств (0 - погашен вовремя, 1 - просрочка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим (там, где менее 7500), что есть пропуски. Это касается 'Annual Income', т.е. не у всех известен годовой доход. Что касается поля 'Month since last delinquent', то пропуски (NaN) можно заменить большим числом (фактически не было правонарушений). Таким числом может быть практически бесконечный срок кредита - 50 лет (600 месяцев)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом, каких-то заоблачных значений нет, за исключением, возможно, суммы наибольшего открытого кредита кредита около 1300 млн. руб или текущей суммы кредита около 100 млн. руб. Из таблицы видно, что среднее значение 'Current Default' равно 0.28, что говорит о несбалансированности выборки (в данной выборке \"дефолтников\" около 28%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обработка выбросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Current Loan Amount'\n",
    "ax = sns.boxplot(y = df_train[col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Путем перебора выясняем, что подозрительным является значение \"все девятки\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 99999999\n",
    "sum(df_train[col_name] == val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на статистику данных в этом подозрительном разрезе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train[col_name] == val][set(df_train.columns) - {col_name}].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что это \"недефолтники\" (max и min 'Credit Default' равны 0), а так как недефолтников в выборке больше, то удаление части их не так страшно (тех, у которых подозрительное значение 'Current Loan Amount' 99999999)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим признак 'Maximum Open Credit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Maximum Open Credit'\n",
    "ax = sns.boxplot(y = df_train[col_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 1304726170\n",
    "sum(df_train[col_name] == val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train[col_name] == val][set(df_train.columns) - {col_name}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего особенного, но так как такое значение одно, то принимаем это за выброс и удаляем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[df_train[col_name] == val].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 380052288\n",
    "sum(df_train[col_name] == val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train[col_name] == val][set(df_train.columns) - {col_name}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего особенного. Опять удаляем выброс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[df_train[col_name] == val].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 265512874\n",
    "sum(df_train[col_name] == val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[df_train[col_name] == val][set(df_train.columns) - {col_name}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего особенного.\n",
    "Итого: удаляем наблюдения, у которых признак 'Current Loan Amount' равен 99999999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(df_train[df_train[col_name] == val].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Current Loan Amount'\n",
    "val = 99999999\n",
    "df_train = df_train.drop(df_train[df_train[col_name] == val].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что баланс выборки несколько улучшился (32% дефолтников), но ценой удаления 870 наблюдений (12%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Обработка пропусков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как уже говорилось ранее, заменим NaN в признаке 'Months since last delinquent' на 600 месяцев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Months since last delinquent'\n",
    "val = 600\n",
    "df_train[col_name].fillna(val, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaN в признаке 'Annual Income' заменим условной медианой (условной, т.е. зависящей от 'Credit Default')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[df_train['Credit Default'] == 0]['Annual Income'].median())\n",
    "print(df_train[df_train['Credit Default'] == 1]['Annual Income'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Annual Income'\n",
    "val_0 = df_train[df_train['Credit Default'] == 0][col_name].median()\n",
    "val_1 = df_train[df_train['Credit Default'] == 0][col_name].median()\n",
    "df_train.loc[df_train['Credit Default'] == 0, col_name] = df_train.loc[df_train['Credit Default'] == 0, col_name].fillna(val_0)\n",
    "df_train.loc[df_train['Credit Default'] == 1, col_name] = df_train.loc[df_train['Credit Default'] == 1, col_name].fillna(val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что не обработан признак 'Bankruptcies'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Bankruptcies'\n",
    "df_train[pd.isnull(df_train[col_name])][set(df_train.columns) - set(col_name)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удаляем эти наблюдения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(subset = [col_name], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Остался признак 'Credit Score'. Посмотрим на его значимость (корреляцию с другими, в т.ч с целевой переменной)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = df_train.corr().iloc[:-1, -1].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "sns.barplot(x=corr_with_target.values, y=corr_with_target.index)\n",
    "\n",
    "plt.title('Correlation with target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Default'\n",
    "with_name = 'Credit Score'\n",
    "df_tmp = df_train.copy()\n",
    "df_tmp.dropna(subset = [with_name], inplace = True)\n",
    "limit_bal_with_target_s = df_tmp[[with_name, col_name]]\n",
    "\n",
    "sns.jointplot(x = col_name, y = with_name, data = limit_bal_with_target_s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что 'Credit Score' в данном случае разделен на две области; но, к счастью, оказалось достаточным большие значения разделить на 10, получив восстановленные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Score'\n",
    "threshold = 5000\n",
    "df_train.loc[df_train[col_name] > threshold, col_name] = df_train[df_train[col_name] > threshold][col_name] * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Default'\n",
    "with_name = 'Credit Score'\n",
    "df_tmp = df_train.copy()\n",
    "df_tmp.dropna(subset = [with_name], inplace = True)\n",
    "limit_bal_with_target_s = df_tmp[[with_name, col_name]]\n",
    "\n",
    "sns.jointplot(x = col_name, y = with_name, data = limit_bal_with_target_s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Score'\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.kdeplot(df_tmp.loc[(df_tmp['Credit Default'] == 0), col_name], label = 'No Default')\n",
    "sns.kdeplot(df_tmp.loc[(df_tmp['Credit Default'] == 1), col_name], label = 'Default')\n",
    "\n",
    "plt.title('Credit Score w(cs)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Score'\n",
    "val_0 = df_train[df_train['Credit Default'] == 0][col_name].median()\n",
    "val_1 = df_train[df_train['Credit Default'] == 0][col_name].median()\n",
    "df_train.loc[df_train['Credit Default'] == 0, col_name] = df_train.loc[df_train['Credit Default'] == 0, col_name].fillna(val_0)\n",
    "df_train.loc[df_train['Credit Default'] == 1, col_name] = df_train.loc[df_train['Credit Default'] == 1, col_name].fillna(val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_0)\n",
    "print(val_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделим категориальные переменные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col_names = list(df_train.select_dtypes(include = ['object']).columns)\n",
    "print('Категориальные признаки')\n",
    "print(cat_col_names)\n",
    "tgt_col_names = ['Credit Default']\n",
    "val_col_names = list(set(df_train.columns) - set(cat_col_names) - set(tgt_col_names))\n",
    "print('Числовые признаки')\n",
    "print(val_col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим какие значения могут принимать категориальные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in cat_col_names:\n",
    "    print(name)\n",
    "    print('*************')\n",
    "    print(set(df_train[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим значение NaN в признаке 'Years in current job'; видимо, это означает то, что клиент на данный момент не работает. Категорий много - 33.\n",
    "\n",
    "Проанализируем корреляцию признаков с целевой переменной в разрезе категориальных переменных, определенных выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для построения корреляций признаков с целевой переменной в разрезах значений категориальной переменной col_name\n",
    "def graph_corr(col_name, data, sz):\n",
    "    cols = list(set(df_train[col_name]))\n",
    "    cols = [str(c) for c in cols]\n",
    "    for p in cols:\n",
    "        eq = df_train[col_name].astype('str') == p\n",
    "        count = sum(eq)\n",
    "        corr_with_target = df_train[eq].corr().iloc[:-1, -1].sort_values(ascending = False)\n",
    "        plt.figure(figsize = sz)\n",
    "        sns.barplot(x = corr_with_target.values, y = corr_with_target.index)\n",
    "        plt.title('Correlation with target variable. ' + col_name + ' = ' + str(p) + '. Count = ' + str(count))\n",
    "        plt.xlim([-1, 1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Домовладение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Home Ownership'\n",
    "graph_corr(col_name, df_train, (12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Количество лет на текущей работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Years in current job'\n",
    "graph_corr(col_name, df_train, (12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Цель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Purpose'\n",
    "graph_corr(col_name, df_train, (12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Срочность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Term'\n",
    "graph_corr(col_name, df_train, (12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом вывод таков, что разбиение на категории играет большую роль, и этим пренебрегать не следует, даже если наблюдений мало. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Матрица корреляций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (24, 24))\n",
    "\n",
    "bs_fn = df_train.columns.drop('Credit Default').tolist()\n",
    "\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.heatmap(df_train[bs_fn].corr().round(3), annot = True, linewidths = 0.5, cmap = 'GnBu')\n",
    "\n",
    "plt.title('Correlation matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 8))\n",
    "\n",
    "col_name = 'Credit Default'\n",
    "sns.countplot(x = 'Tax Liens', hue = col_name, data = df_train)\n",
    "plt.title('Tax Liens grouped by target variable')\n",
    "plt.legend(title = 'Target', loc = 'upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в основном признак 'Tax Liens' равен 0 или 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Default'\n",
    "plt.figure(figsize = (12, 4))\n",
    "sns.kdeplot(df_train.loc[(df_train['Tax Liens'] == 0), col_name], label = 'TL 0')\n",
    "sns.kdeplot(df_train.loc[(df_train['Tax Liens'] == 1), col_name], label = 'TL 1')\n",
    "\n",
    "plt.title('Target')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что пропорции Default/No default примерно одинаковы как при TL = 0, так и при TL = 1, поэтому признак 'Tax Liens' исключаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Отбор признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще раз взглянем на корреляцию признаков с целевой переменной 'Credit Default'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = df_train.corr().iloc[:-1, -1].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "sns.barplot(x = corr_with_target.values, y = corr_with_target.index)\n",
    "\n",
    "plt.title('Correlation with target variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в общем и целом 'Credit Score' антикоррелирован с целевой переменной, что логично (чем выше 'Credit Score', тем вероятнее выдача кредита, т.е. 'Credit Default' = 0). Также и годовой доход, 'Annual Income'. Признак 'Bankruptcies' не коррелирует с целевой переменной, но это еще не означает независимости.\n",
    "\n",
    "Посмотрим на разные сочетания пар признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = 'Bankruptcies'\n",
    "col_2 = 'Credit Default'\n",
    "show_joint = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Совместная плотность w(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train[[col_1, col_2]]\n",
    "\n",
    "if show_joint:\n",
    "    sns.jointplot(x = col_1, y = col_2, data = tmp)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Безусловная плотность w(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train[col_1]\n",
    "sns.distplot(tmp, norm_hist = 'True')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Безусловная плотность w(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train[col_2]\n",
    "sns.distplot(tmp, norm_hist = 'True')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как \"на глазок\" w(x,y) = w(x) w(y), то можно сделать вывод о независимости 'Credit Default' от 'Bankruptcies' и удалить 'Bankruptcies', тем более он коррелирует (r = 0.73) с 'Number of Credit Problems'. Дальше пойдем более простым путем: будем оценивать условные среднее значение и среднеквадратическое отклонение и их безусловные значения (т.е. оценки плотностей заменим на оценки двух моментов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = 'Monthly Debt'\n",
    "col_2 = 'Credit Default'\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].mean())\n",
    "print(df_train[df_train[col_2] == 1][col_1].mean())\n",
    "print(df_train[col_1].mean())\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].std())\n",
    "print(df_train[df_train[col_2] == 1][col_1].std())\n",
    "print(df_train[col_1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что условные от безусловного не особенно отличаются (критериями согласия пренебрегаем), значит можно пренебречь признаком 'Monthly Debt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = 'Months since last delinquent'\n",
    "col_2 = 'Credit Default'\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].mean())\n",
    "print(df_train[df_train[col_2] == 1][col_1].mean())\n",
    "print(df_train[col_1].mean())\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].std())\n",
    "print(df_train[df_train[col_2] == 1][col_1].std())\n",
    "print(df_train[col_1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично пренебрегаем признаком 'Months since last delinquent'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 = 'Current Credit Balance'\n",
    "col_2 = 'Credit Default'\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].mean())\n",
    "print(df_train[df_train[col_2] == 1][col_1].mean())\n",
    "print(df_train[col_1].mean())\n",
    "\n",
    "print(df_train[df_train[col_2] == 0][col_1].std())\n",
    "print(df_train[df_train[col_2] == 1][col_1].std())\n",
    "print(df_train[col_1].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А вот признаком 'Current Credit Balance' пренебрегать не следует."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_for_drop = ['Bankruptcies', 'Monthly Debt', 'Months since last delinquent', 'Tax Liens']\n",
    "try:\n",
    "    df_train.drop(columns = cols_for_drop, inplace = True)\n",
    "except:\n",
    "    print('Columns were deleted')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обзор object-признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat_colname in df_train.select_dtypes(include = 'object').columns:\n",
    "    print(str(cat_colname) + '\\n\\n' + str(df_train[cat_colname].value_counts()) + '\\n' + '*' * 100 + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть чаще всего кредит берут краткосрочный, для того чтобы создать единый кредитный счет (debt consolidation) с пониженной ставкой, при этом работают на одной работе более 10 лет и имеют ипотеку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train) - df_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже говорили, NaN в поле 'Years in current job' пропуском не считается. Однако, заменим NaN на 'None' (нет текущей работы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Years in current job'\n",
    "df_train[col_name].fillna('None', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train) - df_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Анализ данных\\n\",\n",
    "    \"5. Отбор признаков\\n\",\n",
    "    \"6. Балансировка классов\\n\",\n",
    "    \"7. Подбор моделей, получение бейзлана\\n\",\n",
    "    \"8. Выбор наилучшей модели, настройка гиперпараметров\\n\",\n",
    "    \"9. Проверка качества, борьба с переобучением\\n\",\n",
    "    \"10. Интерпретация результатов\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Прогнозирование на тестовом датасете**\\n\",\n",
    "    \"1. Выполнить для тестового датасета те же этапы обработки и постронияния признаков\\n\",\n",
    "    \"2. Спрогнозировать целевую переменную, используя модель, построенную на обучающем датасете\\n\",\n",
    "    \"3. Прогнозы должны быть для всех примеров из тестового датасета (для всех строк)\\n\",\n",
    "    \"4. Соблюдать исходный порядок примеров из тестового датасета\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выделение dummy-переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in df_train.select_dtypes(include = 'object').columns:\n",
    "    df_train = pd.concat([df_train, pd.get_dummies(df_train[c], prefix = c)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение обучающего датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('prep_train.csv', index = False, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target(df, target_name):\n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.idxmax()\n",
    "    minor_class_name = target_counts.idxmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "\n",
    "    for i in range(disbalance_coeff):\n",
    "        sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "        df = df.append(sample, ignore_index = True)\n",
    "\n",
    "    return df.sample(frac = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'Credit Default'\n",
    "df_balanced = balance_df_by_target(df_train, col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После балансировки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[col_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До балансировки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[col_name].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Подбор моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score, learning_curve\n",
    "from sklearn.model_selection import KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_NAMES = df_train.select_dtypes(include = 'float64').columns.to_list()\n",
    "TARGET_NAME = 'Credit Default'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_norm = df_balanced.copy()\n",
    "df_norm[NUMERIC_FEATURE_NAMES] = scaler.fit_transform(df_norm[NUMERIC_FEATURE_NAMES])\n",
    "\n",
    "df = df_norm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_train_true, y_train_pred, y_test_true, y_test_pred):\n",
    "    print('TRAIN\\n\\n' + classification_report(y_train_true, y_train_pred))\n",
    "    print('TEST\\n\\n' + classification_report(y_test_true, y_test_pred))\n",
    "    print('CONFUSION MATRIX\\n')\n",
    "    print(pd.crosstab(y_test_true, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    BASE_FEATURE_NAMES = list(set(df_base.columns.drop(TARGET_NAME).tolist()) - set(cols_for_drop))\n",
    "except:\n",
    "    print('Columns were droped')\n",
    "try:\n",
    "    NEW_FEATURE_NAMES = df.columns.drop([TARGET_NAME] + BASE_FEATURE_NAMES).tolist()\n",
    "except:\n",
    "    print('Columns were droped')\n",
    "FEATURE_NAMES_SELECTED = NUMERIC_FEATURE_NAMES + NEW_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_FEATURE_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[FEATURE_NAMES_SELECTED]\n",
    "Y = df[TARGET_NAME]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, shuffle = True, test_size = 0.25, random_state = 231)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train, Y_train)\n",
    "\n",
    "Y_train_pred = model_lr.predict(X_train)\n",
    "Y_test_pred = model_lr.predict(X_test)\n",
    "\n",
    "get_classification_report(Y_train, Y_train_pred, Y_test, Y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогнозирование на тестовом датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_train['Home Ownership'], prefix = 'Home Ownership').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
